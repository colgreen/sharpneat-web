<!DOCTYPE html>
<html lang="en">
<head>
    <title>SharpNEAT</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75"/>
    <link rel="stylesheet" href="sharpneat.css" type="text/css" media="screen" />
</head>
<body>
    <div class="banner">      
        <a href="/" title="SharpNEAT">
            <img src="sharpneat_logo_banner.svg" alt="SharpNEAT" class="bannerimage" />
        </a>
    </div>
    <div class="centralcolumn">
        <div class="centralcolumninner">
            <!-- Column divider -->
            <div style="float: left; width: 3.3%">
                <br />
            </div>
            <!-- Pagetop Blurb -->
            <div class="frontpagebubble" ">
                <div style="font-weight:bold; font-size:x-large" align="center">
                    Ideas / To-Do List
                </div>
                <p>This is a bucket list of ideas for future development and direction, and a log of more down to earth tasks such as code tidy ups, external library upgrades, etc.</p>
                <p>Last reviewed / updated 2016-02-21</p>
            </div>
            <br />
            <br />

            <!-- Performance - Floating point precision -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Performance - Floating Point Precision</div>

                <p>Investigate the relative merits of single versus double precision floats.</p>
                <p>
                    There is an open question regarding how much precision is required in neuro-evolution methods.
                    For AI methods that learn weights by gradient following there is an argument to allow very small
                    gradient to be followed, otherwise learning may stop. In NEAT a very similar question arises - what
                    is the smallest useful weight change/delta when mutating a connection weight? And can that smallest
                    level of precision be represented by single precision floats
                </p>
                <p>
                    A single precision float is 32 bits (4 bytes); double precision is 64bits (8 bytes). Therefore there
                    is a potential speed improvement to be gained by using less precision, in terms of fitting more weights
                    into CPU caches, efficient use of memory bandwidth and the ability to apply SIMD instructions to 2x as
                    many weights in one operation (at time of writing 256 bit SIMD instructions are common and 512 bit
                    instructions will be available soon, 512/32 = 16 floats)
                </p>

                <p>A broader question might be whether the precision could be reduced further, given the existence of 
                <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">half precision floats</a></p>

                <h5>Notes / Links</h5>
                <ul>
                    <li><a href="https://devblogs.nvidia.com/parallelforall/new-features-cuda-7-5/">New Features in CUDA 7.5: 16-bit Floating Point (FP16) Data</a></li>
                    <li><a href="https://software.intel.com/en-us/articles/performance-benefits-of-half-precision-floats">Performance Benefits of Half Precision Floats</a></li>
                    <li><a href="https://en.m.wikipedia.org/wiki/Half-precision_floating-point_format#IEEE_754_half-precision_binary_floating-point_format:_binary16">IEEE 754 half-precision binary floating-point format: binary16</a></li>
                    <li><a href="http://stanford.edu/~rezab/nips2014workshop/slides/jeff.pdf">Techniques and Systems for Training Large Neural Networks Quickly, Jeff Dean, Google</a> - "Neural nets are very tolerant of reduced precision:
  8 bits or less for inference
 12 to 14 bits for training", pg 41</li>
                </ul>
                <h5>Response from <a href="http://www.sifter.org/~brandyn">Brandyn Webb</a></h5>
                <p>
                    Fwiw, I seem to recall productively reducing at least some of the weights
                    in Inkwell (Apple's handwriting recognition engine) to 8 bit logarithmic
                    values (expanded on the fly via a small lookup table).  We'd periodically
                    discretize them this way during training so that over time the weights could
                    compensate for eachothers' discretization errors (otherwise if you just lop
                    blindly at the end the odds are too high of systematic shifts that add up
                    over large numbers of weights).  In general I think the more abstract the
                    representation, the less granularity you need.  That is, whether a pixel is
                    brighter than its neighbor or not can require quite a precise measurement,
                    and this can matter, as can precise averages over a large number of noisy
                    pixels; but usually whether something is a dog or a tree, and the relative
                    implications thereof, is relatively high contrast--it's not that borderline
                    cases never exist, but just that they're increasingly rare as you ascend
                    the hierarchy of abstraction.  You also generally have far fewer examples
                    of more abstract concepts, so there's often little basis for a high precision
                    tally thereof.
                </p>
            </div>
            <br />

            <!-- Performance - ReLU (Rectified Linear Units) -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Performance - ReLU (Rectified Linear Units)</div>
                <p>
                    The <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> activation function is currently
                    in widespread use in AI neural net models; it is considerably simpler to compute compared to the 
                    <a href="https://en.wikipedia.org/wiki/Logistic_function"> logistic sigmoid, which has been the default
                    in SharpNEAT since its inception.</a>
                </p>
                <p>
                    The simplicity of the ReLU computation will likely result in a significant performance improvement over the logistic 
                    sigmoid. Some investigation is required to evaluate the scale of the improvement (with some thought given to SIMD based
                    code also), and what the implications are to the wider efficacy of neuro-evolution when using an activation with such
                    a significant difference from the function that has formed the basis of most neuro-evolution research to date.
                </p>
                <h5>Notes</h5>
                <p>Leaky Relus is defined as y = (x if x&gt;0, .01x if x&lt;0), which is similar but possesses a nonzero gradient for negative values so that it can still learn.</p>
            </div>
            <br />

            <!-- Performance - SIMD & Vectorisation -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Performance - SIMD &amp; Vectorisation</div>
                <p>
                    SharpNEAT does not currently utilise any of the vector instruction available in modern CPUs. A key issue has been the 
                    lack of support for SIMD in the .NET framework. As of .NET 4.6 the new RyuJIT compiler will generate some SIMD
                    instructions when in 64bit mode and when the .NET System.Numerics.Vector classes are in use. There is a limited 
                    set of SIMD functionailty being exposed via .NET 4.6, but it is worthy of investigation not least because it 
                    ought to be a relatively simple exercise to use the available Vector classes where possible, e.g. in the neural network
                    classes.
                </p>
                <h5>C++/CLI</h5>
                <p>
                    To more fully utilise SIMD in modern CPUs (including the coming 512bit wide vector instructions due from Intel CPUs in 2016), 
                    it's necessary to run code outside of the .NET managed runtime. The most promising option here appears to be the 
                    <a href="https://en.wikipedia.org/wiki/C%2B%2B/CLI">C++/CLI</a> language/environment, this provides an environment where
                    C++ targeting the native CPU can be written, but interaction with the managed runtime is also possible.
                </p>
                <p>
                    Also worth noting at here is that in recent years server CPUs (e.g. Intel Xeons) have tended to use the increasing 
                    transistor count budget to increase core count, with up to 20 cores possible at time of writing. Whereas desktop CPUs
                    have followed a different path of integrating a GPU and other systems previously living on dediciated chips/circuitry off CPU.
                    At this time (2016) it's worth investigating the very significantly higher CPU resources available on server CPUs. This is
                    perhaps not a point that is widely discussed because in the past CPU evolution was mostly on a single path, but now appears
                    to have forked into at leat two two very different paths (server and consumer CPUs).
                </p>
                <h5>Notes / Links</h5>
                <ul>
                    <li><a href="http://www.codeproject.com/Articles/19354/Quick-C-CLI-Learn-C-CLI-in-less-than-minutes">Quick C++/CLI - Learn C++/CLI in less than 10 minutes</a></li>
                    <li><a href="https://msdn.microsoft.com/en-us/library/68td296t.aspx">.NET Programming with C++/CLI (Visual C++)</a></li>
                    <li><a href="http://stackoverflow.com/questions/35525556/under-what-conditions-does-the-net-jit-compiler-perform-automatic-vectorization">Under what conditions does the .NET JIT compiler perform automatic vectorization?</a></li>
                </ul>
            </div>
            <br/>

            <!-- Performance Tests - Speed and NEAT Efficacy  -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Performance and Efficacy Tests</div>
                <p>
                    This idea relates to how we compare the relative merits of changes to the NEAT algorithm. Ultimately we want
                    results in the form of neural networks that implement some desired functionaility, and we want to find these
                    networks as fast as possible.
                </p>
                <p>
                    The idea then is to run NEAT on a some well defined problem domain, e.g. 6-Multiplexer, a large number of times,
                    record the clock time to find the solution, and plot the distribution of clock times. If we now make some change
                    to NEAT, such as changing mutation rates, or how speciation works, etc. we can compare the distributions before
                    and after the change, and therefore have hard empirical evidence regarding the relative efficacy of a high level 
                    modification to the NEAT algorithm.
                </p>
                <p>
                    Note that it's possible to plot distributions of other variable, such as number of evaluations or generations, or
                    even how many Joules of energy were consumed to find a solution (e.g. for different CPUs). The appraoch is broad 
                    enough for performing many different types of comparison, however, my focus is on the NEAT method and the SharpNEAT
                    code base in particular. This is certainly a technique that applies to changes to the NEAT method, but also 
                    to low-level performance optimisations that don't change the NEAT method.
                </p>
            </div>
            <br />

            <!-- Microsoft Unity Inversion of Control (IoC) -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Microsoft Unity Inversion of Control (IoC)</div>
                <p>
                    This idea relates to the SharpNEAT interfaces such IExperiment and INetwork. Instances of these interfaces are 
                    'wired-up' to form a working experiment. Currently the object instantiation and wiring-up is performed by custom code 
                    within SharpNEAT. This custom code can be replaced with an IoC framework that hopefully simplifies the code,
                    improves readability, and allows people working on the code to use and learn a re-usable skill and code library.
                </p>
                <h5>Notes / Links</h5>
                <ul>
                    <li><a href="http://stackoverflow.com/questions/608585/can-someone-explain-microsoft-unity">Can someone explain Microsoft Unity?</a></li>
                    <li><a href="https://msdn.microsoft.com/en-us/library/dn223671(v=pandp.30).aspx">Developer's Guide to Dependency Injection Using Unity</a></li>
                    <li><a href="https://msdn.microsoft.com/en-us/library/ff647202.aspx">Unity Container, Patterns & Practices Developer Center</a></li>
                </ul>
            </div>
            <br />


            <!-- Review 2D Physics Engine -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Review 2D Physics Engine</div>
                <p>
                    Some of the experiments shipped with SharpNEAT use the <a href="https://code.google.com/archive/p/box2dx/">box2dx</a> 
                    physics engine.
                </p>
                <p>
                    There is a detailed overview of situation regarding use of this 2D physics engine and the rendering library being used with it, 
                    at <a href="https://github.com/colgreen/box2dx/blob/master/README.md">gihub.com/colgreen/box2dx</a>. Ultimately it may be wise
                    to switch to another 2D engine such as the <a href="https://farseerphysics.codeplex.com/">Farseer Physics Engine</a>, although
                    there is also some debate about the 
                    <a href="https://www.reddit.com/r/gamedev/comments/2sy9a8/is_there_a_successor_to_farseer_for_c_2d_physics/">status of that project</a>.
                </p>
            </div>
            <br />

            <!-- Unity Game Engine Integration -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Unity Game Engine Integration</div>

                <p>
                    There is at least one github repository that has integrated SharpNEAT and the <a href="https://unity3d.com">Unity game engine</a>
                    (not to be confused with the Microsoft Unity IoC framework); located at 
                    <a href="http://github.com/lordjesus/UnityNEAT">github.com/lordjesus/UnityNEAT</a>.
                </p>
                <p>
                    The changes requried to make this integration work appear to be relatively modest, and therefore it's worth looking into 
                    whether the SharpNEAT core library classes could be re-organised slightly and Unity integration provided as part of the
                    main SharpNEAT project.
                </p>
            </div>
            <br />

            <!-- General Code Refactor -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">General Code Refactor</div>
                <p>
                    Most code bases have room for improvement, and SharpNEAT is no exception. One area I would like to visit is the size of some
                    of the classes in terms of lines of code (LOC) and cyclomatic complexity, and also the size of some methods/functions.
                </p>
                <p>
                    Over the last few years I've adopted a rough heuristic of keeping classes to less than 400 LOC (300 ideally), and methods
                    substantially less than that. This isn't a hard rule, but generally larger classes are a good proxy for poor design choices
                    and defects. So a revisit of the code with these ideas in mind is planned.
                </p>
            </div>
            <br />

            <!-- General Performance Review -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">General Code Refactor</div>
                <p>
                    It's been a few years since I last performance profiled and tuned SharpNEAT. As such it's probably worth doign again now that
                    a number of underlying factors have changes, such as the .NET CLR, JITter (RyuJIT), garbage collector, operating systems 
                    (e.g. Windows 10), CPUs and memory bandwidth, etc.
                </p>
            </div>
            <br />

            <!-- Speciation Research -->
            <div class="frontpagebubble">
                <div style="font-weight:bold" align="center">Speciation Research</div>
                <p>
                    I have this vague idea that speciation by comparing genomes is possibly flawed in some significant ways; this fits the
                    narrative around the novelty search research, and how following an objective function may not lead you to the desired
                    objective.
                </p>
                <p>
                    For now the ideas under this heading are best covered by a number of fairly rambling blog posts, which I hope to condense
                    into something more concrete at some future time...
                </p>

                <ul>
                    <li><a href="http://the-locster.livejournal.com/140308.html">EC Notes</a></li>
                    <li><a href="http://the-locster.livejournal.com/140704.html">EC Notes II</a></li>
                    <li><a href="http://redcalx.livejournal.com/180809.html">Evolutionary Selection and N-Dimensional Density Fields</a></li>
                    <li><a href="http://redcalx.livejournal.com/181086.html">Evolutionary Strategy Space - General Approach for Evolved Neural Nets</a></li>
                    <li><a href="http://redcalx.livejournal.com/181438.html">Evolutionary Strategy Space - Sampling (Notes)</a></li>
                    <li><a href="http://redcalx.livejournal.com/181580.html">Evolutionary Strategy Space - Sampling II</a></li>
                </ul>
            </div>
            <br />
        <br />
        <hr />
        <div class="frontpagefooter">
            Contact: <a href="mailto:colin.green1@gmail.com">Colin Green</a><br /></li>
            SharpNEAT is a <a href="http://heliosphan.org/">Heliosphan.org</a> project.<br /></li>
            Bitcoin: <a href="bitcoin:16u3U7s5UrzjCtcqtXLYQj7jZaUn4cEDbn">16u3U7s5UrzjCtcqtXLYQj7jZaUn4cEDbn</a><br />
        </div>
        <br />
    </div>
</body>
</html>
